\documentclass[11pt]{article}

\usepackage{graphicx}
%\usepackage{algorithmic}
%\usepackage{algorithm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[mathscr]{euscript}
\usepackage{mathtools}
\usepackage{amsmath}

\begin{document}

\pagenumbering{arabic}

\begin{center}
{\LARGE{\textbf{Uncertainty in Artificial Intelligence}}} \\
\Large\textsc{Ph.D. Comprehensive Exam} \\[1em]
\large\textnormal{Mohammad Shayganfar - mshayganfar@wpi.edu} \\
\large\textnormal{May, 26 2015}
\end{center}

\section{Introduction to Uncertainty in AI}

Problems with a large number of variables require maintaining large joint
distributions to compute posterior probabilities based on evidence.

\section{Theories of Uncertainties}

\subsection{Bayesian Belief Networks}

A \textit{Bayesian Belief Network} \cite{pearl:probabilistic-reasoning} is a 
directed acyclic graph consisting of nodes and edges which provides a graphical
model for reasoning under uncertainty. Each node in the network represents a
random variable from the domain. The state of each node is called
\textit{belief} which based on the prior evidence reflects the posterior
probability distribution of the other values associted with that node. Each node
also has an associated \textit{Conditional Probability Table} (CPT) which
represents the coniditonal probability of the variable given the value of its
parents in the graph. Each individual edge between two variables represents the
relation or conditional dependence between those two variables. Also, the
explicit directions represented by arrows as directinoal edges are the notion of
the causality in the network (see Figure \ref{fig:bbn}). They are always drawn
from cause nodes to effect nodes, indicating dependencies between variables
\cite{das:decision-making-agents}. Assuming discrete variables, the strength of
the relationship between variables is quantified by conditional probability
distributions associated with each node.

Constructing a belief network can be divided into two different subtasks: a)
specifying the causal structure among the existing variables in the netwrok, and
b) specifying the prior and conditional probabilies for these variables.

\subsubsection{Network's Structure}

The structure, or topology, of the network captures qualitative relationships
between variables (see Figure \ref{fig:bbn}). The first step in building the
Bayesian network's structure is to determine what are the nodes/variables to
represent in the structure, and what are their possible values? For instance,
nodes with discrete values can have boolean (to represent that a proposition is
true or false), ordered (e.g., enumeration), and integral values (e.g., height
of a person). Then, one should determine the exisiting causality between nodes,
i.e., to determine which node (parent) influences the other (child) and conncet
them through directed edges \cite{korb:bayesian-ai}.

\begin{figure}[tbh]
  \center
  \includegraphics[width=0.6\textwidth]{figure/bbn.png}
  \caption{A Belief Network for a lung cancer problem
  \cite{korb:bayesian-ai}.}
  \label{fig:bbn}
\end{figure}

\subsubsection{Conditional Probability Table}

As we mentioned earlier, after specifying the structure of a Bayesian
Network, the next step is to quantify the relationships between connected nodes
by specifying the conditional probability distribution for each node. These
conditional probability distributions appear as the \textit{Conditional
Probability Tables} (CPT) if we consider discerete variables in the structure.
To calculate values in CPTs, for each node, we need to think about all possible
combinations of values of parent nodes. Each row in a CPT will contain the value
of a conditional probability of a node for each case of the possible combination
of values for the parent node. Clearly, a node has many parents or a node with
the parents taking a large number of values, can cause creating very large CPTs.
The size of the CPT is exponential in the number of parents. For instance, if
the nodes of a network are boolean, a variable with \textit{n} parents requires
a CPT with $2^{n+1}$ probabilities. The probabilities in a CPT are typically
acquired from experts of the subject, but they can also be learned automatically
using machine learning approaches. Figure \ref{fig:bbn} shows variables, their
relations, and associated CPTs for diagnosis of a lung cancer problem taken from
\cite{korb:bayesian-ai}.

\subsubsection{Markov Property}
\label{sec:markov-property}

In Bayesian Networks, each variable is independent of its non-descendants given
its parent variables. Therefore, there are no direct dependencies in the system
being modeled other than those already explicitly shown via edges. Meaning,
there is no hidden connection between variables. This is called \textit{Markov
property} in a Bayesian Network. If Bayesian Networks do not adhere to Markov
property, there will be redundant edges that connect independent variables
together. Consequently, the network will not represent a minimal model.

\subsubsection{Joint Probability Distribution}

In many applications of probability, there are more than one random variable to
be measured over the same sample space (e.g., existence of multiple causes
for a lung cancer). A Bayesian Network provides a complete description of the
domain. Once we identify random variables and their probabilistic relationships,
the values in a joint probability distribution can then be obtained from the
probabilities relating the random variables. Therefore, all the entries in the
full joint probability distribution can be calculated from the information in
the network. There is also a fundamental assumption that in the underlying
structure of the problem being modeled by a Bayesian Network, not every single
node is connected to every other one \cite{korb:bayesian-ai}. Therefore, if
there is such a problem structure, then Bayesian Network can provide a compact
representation of a model for that problem. In the following formula
\textit{P($x_1, x_2, \ldots, x_n$)} is an abbreviation for the conjuction of
\textit{\textbf{n}} assignments to each variable. Hence, the following formula
gives the value of each variable:

\begin{center}
$P(x_1, x_2, \ldots, x_n) = \prod\limits_{i=1}^{n} P(x_i | parents (X_i))$\\	
\end{center}

\noindent where \textit{parents($X_i$)} denotes the specific values of the
variables in \textit{Parents($X_i$)}. As we see, given Markov property, the
product of only the appropriate elements (parent nodes) of the CPTs in the
network represents the value of each individual entry in the joint probability
distribution. The following provides an example based on the network provided in
Figure \ref{fig:bbn}.\\

\begin{footnotesize}
\noindent $P(X= pos \wedge D = true \wedge C = false \wedge P = high \wedge S =
true)$\\

\noindent $= P(X= pos | D = true , C = false , P = high , S = true)$

\noindent $\times P(D = true | C = false , P = high , S = true)$

\noindent $\times P(C = false | P = high , S = true) \times P(P = high| S =
true) \times P(S = true)$\\

\noindent $= P(X= pos | C = false) \times P(D = true | C = false) \times P(C =
false | P = high , S = true) \times P(P = high) \times P(S = true)$
\end{footnotesize}

\subsubsection{Reasoning in Bayesian Networks}

Reasoning in Bayesian Networks is the process of updating beliefs in face of the
evidences. In other words, it is the process of efficiently deducing the belief
distribution over a particular subset of random variables given that we know
the states of some other variables in the network. Bayesian Networks can be
conditioned upon any subset of their variables, supporting any direction of
reasoning. Figure \ref{fig:reasoning-types} shows four different types of
reasoning using the network shown in Figure \ref{fig:bbn}. These four types are
reasoning are \cite{korb:bayesian-ai}:\\

\textbf{Diagnostic reasoning} -- This is the reasoning from symptoms (effects)
to cause. For instance, a doctor updates her belief about a patient's cancer
when she checks the X-ray results.

\textbf{Predictive reasoning} -- This is the reasoning based on new information
about the causes to new beliefs about the corresponding effects. For instance,
if the patient tells his doctor the information about the polluted area he
lives, the doctor's belief about the patient having cancer increases, even
without assessing patient's symptoms.

\textbf{Intercausal reasoning} -- This is the reasoning about the mutual causes
of a common effect. For instance,  suppose that there are two different causes
for lung cancer, smoking and pollution (see Figure \ref{fig:bbn}). Initially
these two causes are independent of each other; i.e., the patient smoking or
not, does not change the parobability of the patient being subject to pollution.
However, as soon as the patient is diagnosed with cancer, the probability of
smoking or living in a polluted area increases. Now, if the doctor discovers
that her patient is a smoker, then the probaility of him living in polluted area
dicreases. Therefore, the presence of one explanatory cause for the cancer
lowers the probability of the alternative cause, even though that they both were
independent causes. In other words, the first explanatory cause \textit{explains
away} the alternative one.

\textbf{Combined reasoning} -- Sometimes the reaosning does not fit to one of
the explained types. Thus, any of these reasoning types can be combined to solve
a problem.

\begin{figure}[tbh]
  \center
  \includegraphics[width=0.65\textwidth]{figure/reasoning-types.png}
  \caption{Types of Reasoning \cite{korb:bayesian-ai}.}
  \label{fig:reasoning-types}
\end{figure}

\subsubsection{Conditional Independence}
\label{sec:conditional-independence}

Bayesian networks which satisfy the Markov property (see Section
\ref{sec:markov-property}) explicitly express conditional independencies in
probability distributions \cite{korb:bayesian-ai}. Therefore, since a Bayesian
Network is based on joint probability distribution of a set of random variables,
the knowledge about conditional independence of these random variables is
important for understanding of reasoning based on conditinal probailities. 

Two random variables \textit{A} and \textit{B} are \textit{conditionally
independent} given another variable \textit{C}, if $p(A,B|C) = p(A|C).p(B|C)$,
therefore:

\begin{center}
$p(A|B,C) = \frac{p(A,B|C)}{p(B|C)} = \frac{p(A|C).p(B|C)}{p(B|C)} = p(A|C)$
\end{center}

\noindent And similarly, $p(B|A,C) = p(B|C)$. Figure
\ref{fig:conditional-independence}(a) shows a \textit{causal chain} between
\textit{A} and \textit{B} and \textit{C}. For instance, the fact that being a
smoker can cause lung cancer which causes shortness of breath, in our example.
This kind of causal chains can cause a conditional independence which can be
described as: $P(C|A,B) = P(C|B)$. This means that if one already knows that
\textit{C} has occurred, knowing that \textit{A} occurred doesn’t make a
difference to one's beliefs about \textit{C}. Figure
\ref{fig:conditional-independence}(b) shows that both variables \textit{A} and
\textit{C} have a \textit{common cause} called \textit{B}. For instance, based
on our example, lung cancer is a common cause for a positive x-ray and dyspnoea
in patient. This kind of common causes can also cause a conditional independence
which , again, can be described as: $P(C|A,B) = P(C|B)$. This means that if one
already knows about \textit{B}, then an additional information that \textit{A}
provides, will not give more information about the chances of \textit{C}. Figure
\ref{fig:conditional-independence}(c) shows that one variable has two causes.
\textit{Common effect} produces the opposite conditional independence to that of
common causes and causal chains. This means that parents are independent until
the common effect provides new information. This kind of common effects can
cause a conditional dependence which can be described as: $P(A|B,C) \neq
P(A|B)$. In other words, if one knows about \textit{B} (the effect), then finds
out that for example \textit{A} (one of two causes) is absent, this increases
the probability of \textit{C} (alternative cause).

\begin{figure}[tbh]
  \center
  \includegraphics[width=0.8\textwidth]{figure/conditional-independence.png}
  \caption{(a) causal chain, (b) common cause, and (c) common effect
  \cite{korb:bayesian-ai}.}
  \label{fig:conditional-independence}
\end{figure}

\subsubsection{d-Separation}

The concepts of conditional dependencies and independencies, discussed above,
can apply not only between pairs of nodes, but also between sets of nodes. In
general, it is possible to determine wheter two sets of nodes \textit{X} and
\textit{Y} are independent, if there is a set of evidence nodes \textit{E},
given the Markov property. If the two sets of nodes \textit{X} and \textit{Y}
are \textit{d-separated} (directional-dependent separation) by evidence set of
nodes \textit{E}, then (given the Markov property) the two sets of nodes
\textit{X} and \textit{Y} are conditionally independent given \textit{E}.
d-separation is a topological criterion for Bayesian Networks
\cite{russell:ai-modern}. Figure \ref{fig:d-separation} shows how the evidence
set of nodes \textit{E} in three different conditions is blocking the two sets
of nodes \textit{X} and \textit{Y}. In a graph, a path is blocked given a set of
nodes \textit{E}, if there is a node \textit{Z} on the path for which at least
one of the three conditions discussed in Section
\ref{sec:conditional-independence} holds.

\begin{figure}[tbh]
  \center
  \includegraphics[width=0.55\textwidth]{figure/d-separation.png}
  \caption{Three types of situations in which the path from \textit{X} to
  \textit{Y} can be blocked, given evidence \textit{E}. In each case, \textit{X}
  and \textit{Y} are d-separated by \textit{E}
  \cite{korb:bayesian-ai}.}
  \label{fig:d-separation}
\end{figure}

Analogous to our example, based on this definition the pollution and smoking
variables are d-separated from x-ray and dyspnoea (blocking condition 1), x-ray
is d-separated from dyspnoea (blocking condition 2), and if cancer and x-ray or
dyspnoea are not observed, then smoking variable would have been d-separated
from pollution (blocking condition 3).

\subsection{Dempster-Shafer Theory}

In \cite{dempster:theory}, Dempster proposed a probabilistic framework based on
lower and upper bounds on probabilities. In \cite{shafer:evidence-theory},
Shafer developed a formalism for reasoning under uncertainty which uses some of
Dempster's mathematical expressions with different interpretation. Based on
Shafer's formalism, each piece of evidence may support a subset containing
several hypotheses. This is a generalization of the pure probabilistic framework
in which every finding corresponds to a value of a variable (a single
hypothesis) \cite{diez:reasoning-uncertainty}. Therefore, Dempster-Shafer theory
is the generalization of the Bayesian theory of subjective probability to
combine accumulative evidence or to change prior opinions in the light of new
evidence \cite{das:decision-making-agents}. Dempster-Shafer theory is designed
to deal with the distinction between uncertainty and ignorance. Rather than
computing the probability of a proposition, it computes the probability that the
evidence supports the proposition \cite{russell:ai-modern}, and it does not
require the assumption that \textit{Belief}(A) + \textit{Belief}($\neg$A) = 1.
Dempster-Shafer theory deals with the possible values of an unknown variable,
just as deos the theory of probability \cite{tanimoto:ai-lisp}.

There are three basic functions in the Dempster-Shafer theory that we need to
understand for modeling purposes, \textit{mass function, belief function}, and
\textit{plausibility function}. Let $\Theta=\{h_1,h_2, \ldots, h_n\}$ be a
finite set of hypotheses. This set of hypotheses is also called \textit{frame of
discerntment}. The hypotheses represent all the possible states of the system
considered. The set of all subsets of $\Theta$ is its \textit{power set}:
$2^\Theta$. A subset of these $2^\Theta$ sets may consist of a single hypothesis
or of a conjunction of several hypotheses (e.g., a snowy day and a dry day). The
pieces of evidence are events that occurred or may occur (e.g., high pressure
shown by a barometer, or low temprature). One piece of evidence can be related
to a single hypothesis or a set of hypotheses. However, it is not allowed to
have different pieces of evidence lead to the same hypothesis or set of
hypotheses. In fact, the relation between a piece of evidence and a hypothesis
corresponds to a cause-effect chain, i.e., a piece of evidence implies a
hypothesis or a set of hypotheses \cite{kay:dst-reliability}. Moreover, it is
required that all hypotheses are unique, not overlapping and mutually exclusive.

\subsubsection{Mass Function}

A \textit{Basic Probability Assignment} (BPA) or \textit{mass function}
is a function $m:2^\Theta\rightarrow[0,1]$ such that:\\

\textit{m}($\emptyset$) = 0, and $\sum\limits_{x\in2^\Theta}m(x) =1$.\\

The value 0 indicates no belief and the value 1 indicates total belief, and
any value between these two indicate partial belief. As you see the mass
function uses the notion of $2^\Theta$ to be able to use all possible subsets of
the \textit{frame of discernment} $\Theta$. All of the assigned probabilities
sum to unity. There is no belief in empty set. Any subset x of the frame of
discernment $\Theta$ for which m(x) is non-zero is called a \textit{focal
element} and represents the exact belief in the proposition depicted by x. Thus,
any subset is proposition and vice versa. Other elements in Dempster-Shafer
theory are defined by mass function. 

\subsubsection{Belief Function}

Now, we can define another important notion in Dempster-Shafer theory, the
\textit{belief function} (sometimes called a \textit{support function}). It is
the measure of total belief committed to $A \subseteq \Theta$ that can be
obtained by simply adding up the mass of all the subsets of \textit{A}. In other
words, given the frame of discernment $\Theta$ and $A \subseteq \Theta$, the
belief in \textit{A}, denoted \textit{Belief}(\textit{A}), is a number in the
interval [0, 1]. Belief in a set of elements, say \textit{A}, of a frame
$\Theta$, represents the total belief that one has based on the evidence
obtained. Unlike probability theory, \textit{Belief}(\textit{A}) = 0 represents
lack of evidence about \textit{A}, while \textit{p}(A) = 0 represents the
impossibility of \textit{A}. However, \textit{Belief}(\textit{A}) = 1 represents
certainty, that is \textit{A} is certain to occur, similar to \textit{p}(A) = 1,
which also represents the certainty that \textit{A} is true. A belief function
defined on a space $\Theta$ must satisfy the following three properties:

\begin{itemize}
	\item[]\textit{Belief}($\emptyset$) = 0
	\item[]\textit{Belief}($\Theta$) = 1
	\item[]\small\textit{Belief}($A_1 \cup \ldots A_n$)
	$\geq \sum\limits_i\textit{Belief}$($A_i$) - $\sum\limits_{i \textless
	j}\textit{Belief}$($A_i \cap A_j$) + \ldots +\\
	$(-1)^{n+1}\textit{Belief}$($A_i \cap \ldots \cap A_n$)
\end{itemize}

\noindent A belief function is a function $Belief:2^\Theta\rightarrow[0,1]$ and
is defined by:\\

\textit{Belief}(\textit{A}) = $\sum\limits_{B \subseteq A}m(B)\qquad$ for all $A
\subseteq \Theta$\\

\subsubsection{Plausibility Function}

Plausibility in a set, say \textit{A} of a frame $\Theta$ consisting of a
mutually exclusive and exhaustive set of elements, represents the maximum
possibility that a set \textit{A} is true given all the evidences. A
plausibility function \textit{Plausible} defined on a space $\Theta$ must satisfy the
following three properties:

\begin{itemize}
	\item[]\textit{Plausible}($\emptyset$) = 0
	\item[]\textit{Plausible}($\Theta$) = 1
	\item[]\small\textit{Plausible}($A_1 \cap \ldots A_n$)
	$\leq \sum\limits_i\textit{Plausible}$($A_i$) - $\sum\limits_{i \textless
	j}\textit{Plausible}$($A_i \cup A_j$) + \ldots +\\
	$(-1)^{n+1}\textit{Plausible}$($A_i \cup \ldots \cup A_n$)
\end{itemize}

A \textit{plausibility} measure is a function
$Plausible:2^\Theta\rightarrow[0,1]$, and is defined by:\\

\textit{Plausible}(\textit{A}) = $\sum\limits_{B \cap A \neq
\emptyset}m(B)\qquad$ for all $A \subseteq \Theta$\\

\noindent \textit{Plausible}(\textit{A}) in a subset \textit{A} is defined to
be the sum of all mass functions for the subsets \textit{B} that have non-zero
intersections with \textit{A}, and it represents the extent to which we fail to
disbelieve \textit{A}. In other words, it corresponds to the total belief that
does not contradict \textit{A}. The plausibility and belief functions are
related to one another, and we can represent this relation as:\\

\noindent\textit{Belief}(\textit{A}) = 1 -
\textit{Plausible}(\textit{$\neg$A}) $\quad$ and $\quad$
\textit{Plausible}(\textit{A}) = 1 - \textit{Belief}(\textit{$\neg$A}),\\

\noindent where \textit{$\neg$A} is \textit{A}'s complement. Also,
\textit{Belief}(\textit{$\neg$A}) is often called the \textit{doubt} in
\textit{A}. It is noteworthy to mention that Dempster-Shafer theory allows the
representation of \textit{ignorance} since \textit{Belief}(\textit{A}) = 0 does
not imply \textit{Belief}(\textit{$\neg$A}) $\textgreater$ 0 even though
\textit{Belief}(\textit{$\neg$A}) = 1 implies \textit{Belief}(\textit{A}) = 0. Other
notable relations are:\\

\noindent\textit{Belief}(\textit{A}) + \textit{Belief}(\textit{$\neg$A}) $\leq$ 1,
and\\

\noindent\textit{Plausible}(\textit{A}) +
\textit{Plausible}(\textit{$\neg$A}) $\geq$ 1.\\

Here, we also note that in the case of each of the focal elements being
singletons then we return back to traditional Bayesian analysis incorporating
normal probability theory, since in this case \textit{Belief}(\textit{A}) =
\textit{Plausible}(\textit{A}) \cite{beynon:dst-alternative-decision}.

\begin{figure}[tbh]
  \center
  \includegraphics[width=0.65\textwidth]{figure/uncertainty.png}
  \caption{Measures of belief and plausibility. The uncertainty interval is
  shaded gray. \cite{kay:dst-reliability}.}
  \label{fig:uncertainty}
\end{figure}

Collectively the above measures provide Dempster-Shafer theory with an explicit
measure of ignorance about \textit{A} and its complement. All the above measures
of confidence and the BPA are equivalent, in the sense that each of them can be
expressed as a function of any one of the rest. The \textit{uncertainty}
measure is defined as the length of the interval [\textit{Belief}(\textit{A}),
\textit{Plausible}(\textit{A})] where \textit{Belief}(\textit{A}) $\leqslant$
\textit{Plausible}(\textit{A}) \cite{yager:dst-combination-rules}, and it is
also called as \textit{belief interval}. Figure \ref{fig:uncertainty}
illustartes a graphical representation of the belief, plausibility, and doubt
measures which we defined above. As it is shown and said earlier, the difference
between plausibility and belief describes the evidential interval range which
represents the uncertainty concerning the set \textit{A}. Also, as we see in
Figure \ref{fig:uncertainty}, lack of belief does not imply disbelief, since the
complements of belief and plausibility are doubt and disbelief, respectuvely.
Furthermore, the mass assigned to $\Theta$ can be interpreted as the global
ignorance, since the level of mass value is not discernible among the
hypotheses.

\subsubsection{Dempster's Rule of Combination}

Suppose that we have two pieces of uncertain evidence relevant to the same frame of
discerntment $\Theta$. Dempster-Shafer theory also provides a method to combine
the measures of evidence from different sources, using Dempster's rule of
combination which combines two pieces of evidence into a single new piece. The
rule assumes that the sources are independent. If $m_1$ and $m_2$ are the BPA's
associated with $Bel_1$ and $Bel_2$ respectively and $Bel_1$ and $Bel_2$ are
independent, then Dempster's rule of combination is as follows:\\

\[
	[m_1 \oplus m_2](y) = 
    \begin{dcases}
      0, & y = \emptyset \\
      \frac{\sum\limits_{A \cap B = y}m_1(A)m_2(B)}{1-\sum\limits_{A
      \cap B \neq \emptyset}m_1(A)m_2(B)}, & y
      \neq
      \emptyset
	\end{dcases}
\]\\

\noindent The numerator, i.e., $\sum\limits{_{A \cap B =y}}m_1(A)m_2(B)$,
represents the accumulated evidence for the sets A and B, which supports the
given hypothesis y. The denominator in the Dempster's rule of combination, i.e.,
$1-\sum\limits{_{A \cap B \neq \emptyset}}m_1(A)m_2(B)$, is an important
normalization factor denoted by $\mathcal{K}$ which can be interpreted as a
measure of conflict between the sources
\cite{srivastava:evidential-reasoning-uncertainty}.

\subsection{Fuzzy Logic Theory}

Fuzzy Logic, introduced by Zadeh in 1965 \cite{zadeh:fuzzy}, provides a
mathematical framework to capture uncertainty. There are different kinds of
uncertainties in the real world. For instance, randomness is one kind, which is
typically modeled using probability theory. Fuzziness manipulates uncertainty by
dealing with the boundaries of a set that are not clearly defined. Fuzzy Logic
is a multivalued logic, that allows intermediate values to be defined between
conventional evaluations like ``true'' and ``false''. Fuzzy Logic's ultimate
goal is to provide foundations for approximate reasoning using imprecise
propositions based on fuzzy set theory. In order to deal with such imprecise
inference, Fuzzy Logic allows the imprecise linguistic terms such as:
fuzzy predicates (e.g., old, expensive), fuzzy quantifiers (e.g., many, little),
and fuzzy truth values (e.g., unlikely false or unlikely true). Fuzzy Logic is a
method for reasoning with logical expressions describing membership in fuzzy
sets \cite{russell:ai-modern}. Logics as bases for reasoning can be
distinguished essentially by three items: truth values, operators, and reasoning
procedures (e.g., tautologies) \cite{zimmermann:fuzzy-sets}. For instance, in
dual logic, truth values can be ``true'' (1) or ``false'' (0), operators can be
defined using the truth tables, and modus ponens or contrapositions can be
considered as tautology. In Fuzzy Logic, the truth values are no longer
restricted to two values, but are expressed by the linguistic variables such as
and including ``true" or ``false". In all forms of fuzzy reasoning, the
implications can be modeled in different ways.

\begin{figure}[tbh]
  \center
  \includegraphics[width=0.95\textwidth]{figure/fuzzy-algorithm.png}
  \caption{Fuzzy Logic algorithm.}
  \label{fig:fuzzy-algorithm}
\end{figure}

Figure \ref{fig:fuzzy-algorithm} shows the Fuzzy Logic algorithm. It begins
with initialization of linguistic varibales (see Section
\ref{sec:linguistic-variables}) and constructing appropriate membership
functions (see Section \ref{sec:membership-function}) and rule-base of the
fuzzy system (see Section \ref{sec:fuzzy-rules}). The constructed membership
functions transform the input data to fuzzy values (see Section
\ref{sec:fuzzification}). Then, the inference system evaluates the constructed
rules with respect to the given input value, and merges the results obtained
from each rule. Finally, the ovelall result will be transformed to a non-fuzzy
(crisp) value (see Section \ref{sec:defuzzification}).

\subsubsection{Probability vs Possibility}

The theory of possibility is analogous and yet conceptually different from the
theory of probability. Based on the Fuzzy Logic theory of Zadeh
\cite{zadeh:fuzzy} there is a difference between possibility of an event
happening and the probability of that. The follwing example by Zimmermann in
\cite{zimmermann:fuzzy-sets} shows the differnce. Consider the statement ``Hans
ate \textit{X} eggs for breakfast'', where \textit{X} $\in$ \textit{U} = $\{1,
2, \ldots, 8\}$. We may associate a probability \textit{p} by observing
\textit{Hans} eating breakfast for 100 days,

\begin{figure}[tbh]
  \center
  \includegraphics[width=0.65\textwidth]{figure/prob-poss-01.png}
  \label{fig:probability}
\end{figure}

A fuzzy set expressing the degree to which \textit{Hans} can eat \textit{X} eggs
in breakfast may be the following possibilty distribution $\pi$,

\begin{figure}[tbh]
  \center
  \includegraphics[width=0.65\textwidth]{figure/prob-poss-02.png}
  \label{fig:ppssibility}
\end{figure}

where the possiibility of \textit{X} = 3 is 1, while the probability of
\textit{Hans} eating 3 eggs for breakfast is only 0.1. Therefore, as the example
shows, a possible event does not necessarily imply that it is probable too.
However, if the event is probable it must also be possible
\cite{zimmermann:fuzzy-sets}.

\subsubsection{Fuzzy Sets}

Fuzzy sets are a further development of the mathematical concept of a
conventional or crisp sets. A fuzzy set is a class of objects with continuum of
degrees of membership \cite{zadeh:fuzzy}. Following Zadeh \cite{zadeh:fuzzy}
many sets have more than an either-or criterion for membership. For insatnce,
the set young people which can contain people at diffrent ages. A fuzzy set
$\textit{A}$ is defined by a membership function $\mu_A$ from the universe of
discourse $\mathcal{X}$ to the closed unit interval [0,1]. We interpret
$\mu_A$($\textit{x}$) as the degree of membership of $\textit{x}$ in \textit{A}
(see Section \ref{sec:membership-function}). Zadeh proposed this degree of
membership, such that the transition from membership to non-membership is
gradual rather than abrupt. Therefore, the degree of membership for all its
members describes a fuzzy set.

\subsubsection{Membership Functions}
\label{sec:membership-function}

\textit{Membership functions} are the crucial part of the Fuzzy Logic theory. In
fact, the difference between crisp (i.e., classical) and fuzzy sets is
established by introducing membership functions. Membership functions are
mathematical tools for indicating flexible membership to a set, modeling and
quantifying the meaning of symbols. Membership functions are used in the
fuzzification and defuzzification steps (see Sections \ref{sec:fuzzification}
and \ref{sec:defuzzification}) of a Fuzzy Logic system. A membership function is
used to quantify a linguistic term (see Section \ref{sec:linguistic-variables}).
Therefore, the manipulation of fuzzy quantities can be accomplished by
manipulation of fuzzy set membership functions. Some of the manipulation
includes set complement, intersection, and union as well as fuzzification and
defuzzification (see Sections \ref{sec:fuzzification} and
\ref{sec:defuzzification}) \cite{schalkoff:intelligent-systems}.

\begin{figure}[tbh]
  \center
  \includegraphics[width=0.65\textwidth]{figure/membership-function.png}
  \caption{Membership functions for the concepts young, mature and old.}
  \label{fig:membership-function}
\end{figure}

Let $\mathcal{X}$ be a crisp universal set. A fuzzy subset $\textit{A}$ of
$\mathcal{X}$ is characterized by a membership function; $\mu_A$ : $\mathcal{X}
\rightarrow$ [0, 1]. $\mu_A$($\textit{x}$) is called the \textit{membership
degree (grade)} of $\textit{x}$ in $\textit{A}$. The degree of membership is
expressed by a real number in the interval [0, 1]. The degree of membership is a
precise, but subjective measure that depends on the context.

Figure \ref{fig:membership-function} shows membership functions for three
linguistic terms of age variable (see also Section
\ref{sec:linguistic-variables}). It shows three examples of a membership
functions in the interval 0 to 70 years. These three functions define the degree
of membership of any given age in the sets of young, mature, and old ages. Note
that, an important characteristic of fuzzy logic is that a numerical value does
not have to be fuzzified using only one membership function. In other words, a
value can belong to multiple sets at the same time. For instance, if someone is
20 years old her degree of membership in the set of young persons is 1.0
(maximum value), in the set of matures 0.35, and in the set of old persons 0.0
(minimum value). As another example, if someone is 50 years old the degrees of
membership in the sets of young, mature, and old are 0.0, 1.0, 0.3 respectively.

Membership functions can have different shapes and their shape can be determined
arbitrarilty based on experience or sometimes by running statistical studies on
data. They can be sigmoidal, heyperbolic, Gaussian or any other shape. The
followings are some of the important properties of fuzzy sets and membership
functions:\\

\textbf{Height:} The height of a fuzzy set $\textit{A}$, denoted by
$\textit{h}$($\textit{A}$), corresponds to the upper bound of the membership
function. In other words, it is the largest membership degree obtained by any
element in that set:\\

$\textit{h}$($\textit{A}$) = sup$\{\mu_A(\textit{x}) | \textit{x} \in
\mathcal{X}\}$.\\

\textbf{Support:} The support of a fuzzy set $\textit{A}$ is a set of all
elements \textit{x} of $\mathcal{X}$ for which (\textit{x}, $\mu_A$(\textit{x}))
$\in$ $\textit{A}$ and $\mu_A$(\textit{x}) $\textgreater$ 0 holds. In other
words, support is a set of all elements of $\mathcal{X}$ that have non-zero
membership degrees in $\textit{A}$.\\

\textbf{$\alpha$-cut:} An $\alpha$-cut of a fuzzy set $\textit{A}$ is the subset
of elements with a membership degree greater than or equal to $\alpha$. The
$\alpha$-cut is denoted by:\\ \\$\alpha$-cut($\textit{A}$) = $\{\textit{x} \in
\mathcal{X} | \mu_A(\textit{x}) \geqslant \alpha\}$.\\

\textbf{core:} The core of a fuzzy set $\textit{A}$ is the crisp set that
contains all the elements of $\mathcal{X}$ that have the membership degrees of
\textbf{one} in $\textit{A}$.

\subsubsection{Linguistic Variables}
\label{sec:linguistic-variables}

The concept of membership function discussed in Section
\ref{sec:membership-function} allows us to define fuzzy systems in natural
language. Linguistic variables are the input or output variables of the system
whose values are words or sentences from a natural language, instead of
numerical values. In fact, just like an algebraic variable takes numbers as
values, a linguistic variable takes words or sentences as values
\cite{zimmermann:fuzzy-sets}. A linguistic variable is generally decomposed into
a set of linguistic terms. For instance, for people's age, we usually use terms
such as ``old'' or ``young'' which are called linguistic values of the age.
Then, we can consider a set of decompositions for the linguistic variable age,
\textit{Age}(\textit{a}) = \{very-old, old, mature, young, very-young\}. The
members of this decomposition set are called \textit{linguistic terms} which can
cover a portion of the overall values of people's age. In other words, the
values that a linguistic variable can take is called its linguistic terms.

\subsubsection{Fuzzy Operators}

Fuzzy operators are used in order to manipulate fuzzy sets, and for being able
to evaluate the constructed fuzzy rules (see Section \ref{sec:fuzzy-rules}), and
ultimately to be able to combine the results of the individual rules. The
operations on fuzzy sets are different than the operations on classical sets.
The definitions of operators on fuzzy sets are not the same and can be
arbitrarily chosen. Zadeh in \cite{zadeh:fuzzy} defined the intersection
(logical and), union (exclusive or), and complement (negation) operations for
fuzzy sets as generalization of crisp sets and of crisp statements. Here are the
operators for the complement (NOT), the intersection (AND) and union (OR)
that are most commonly used:\\

\noindent The memebership function of the \textbf{Intersection} of two fuzzy
sets \textit{A} and \textit{B}:\\

$\mu_{A \cap B}(X)$ = Min($\mu_{A}(X), \mu_{B}(X)$) $\qquad \forall x \in X$\\

\noindent The memebership function of the \textbf{union} of two fuzzy sets
\textit{A} and \textit{B}:\\

$\mu_{A \cup B}(X)$ = Max($\mu_{A}(X), \mu_{B}(X)$) $\qquad \forall x \in X$\\

\noindent The memebership function of the \textbf{complement} of a fuzzy set
\textit{A}:\\

$\mu_{A}(X)$ = 1 - $\mu_{A}(X) \qquad \forall x \in X$\\

\noindent These definitions were later extended by other reasearchers too, e.g.,
\cite{yager:generalizing-leximin}.

\subsubsection{Fuzzy Rules}
\label{sec:fuzzy-rules}

In a Fuzzy Logic system, a rule-base is constructed to determine and control the
output variable. Fuzzy rules are simply comprised of IF-THEN rules which include
two parts of condition and conclusion. A fuzzy rule is encoded in a statement in
the following form:\\

\noindent \textbf{IF} (a statement of conditions is satisfied)

$\qquad\qquad\qquad\qquad\qquad$\textbf{THEN} (a set of consequences can
be inferred).\\

The followings are two examples of fuzzy
rules based on the age example depicted in Figure
\ref{fig:membership-function}:\\

\textbf{IF} (age is \textit{young}) \textbf{THEN} (run \textit{command
``talk''})
 
\textbf{IF} (age is \textit{old} \textbf{OR} \textit{mature}) \textbf{THEN} (run
\textit{command ``listen''})\\

\noindent The rules use the input membership values as weighting factors to
determine their influence on the fuzzy output sets of the final output
conclusion.

\subsubsection{Fuzzification}
\label{sec:fuzzification}

For mapping the crisp values to fuzzy ones, we need to evaluate their membership
degree using membership functions (see Seciton \ref{sec:membership-function}).
This process is called fuzzification and it helps us to get one fuzzy value for
each crisp input. Therefore, the fuzzification process is mainly used to
transform a crisp set to a fuzzy set.

\subsubsection{Reasoning in Fuzzy Logic}
\label{sec:reasoning}

In order to draw conclusions from a rule-base, we need a mechanism that can
produce an output from a collection of IF-THEN rules. Meaning, after evaluating
the result of each rule with respect to the given input value(s), the results of
the rules should be combined to obtain a final result. This process in Fuzzy
Logic systems is called reasoning. Fuzzy reasoning includes two distinct parts:
evaluating the IF part of the rule and applying the result to the consequent
(the THEN part of the rule). In fuzzy systems the evaluation is slightly
different than the classical rule-based systems. In fuzzy systems the IF part of
the rule is a fuzzy statement which means all the rules fire at some extent. If
the IF part of the rule is true in some degree of membership, then the
consequent is also true in some degree. It is noteworthy to mention that the
results of individual rules can be combined in different ways. There are
different types of accumulation methods that can be used to combine the results
in individual rules.

\subsubsection{Defuzzification}
\label{sec:defuzzification}

After the reasoning step, the Fuzzy Logic system provides the overall result as
a fuzzy value. Then, to obtain a final crisp output value, this fuzzy result
should be defuzzified which is the purpose of the defuzzifier component of a
Fuzzy Logic system. Defuzzification is performed according to the membership
function of the output variable. Figure \ref{fig:defuzzification} shows the
defuzzification step in a Fuzzy Logic system.

\begin{figure}[tbh]
  \center
  \includegraphics[width=0.55\textwidth]{figure/cog.png}
  \caption{Defuzzification using Center of Gravity (COG) method
  \cite{antonio:cog-defuzzification}.}
  \label{fig:defuzzification}
\end{figure}

There are different algorithms for defuzzification step. One of the most
widely used algorithms is called \textit{centeroid}, or \textit{Center of
Area}, or \textit{Center of Gravity} (COG). This method computes the center of
area of the region under the curve deÞned by a fuzzy set. In this method, the
defuzzified values tend to move smoothly in reaction to small changes, and it is
relatively easy to compute the value. In the following formula, \textit{A} is
a fuzzy set and $z_{_{COG}}$ is the final single crisp output which in this case
is obtained by COG method:\\

\begin{center}
$z_{_{COG}} = \frac{\sum\limits_{i=1}^{n} \mu_A(z_i).z_j}{\sum\limits_{i=1}^{n}
\mu_A(z_i)}$
\end{center}

In summary, Figure \ref{fig:fuzzy-system} (see also the fuzzy algorithm in
Figure \ref{fig:fuzzy-algorithm}) generally shows the process of fuzzy logic.
Firstly, a crisp set of input data are gathered and converted to a fuzzy set
using fuzzy linguistic variables (see Section \ref{sec:linguistic-variables}),
fuzzy linguistic terms and membership functions (see Section
\ref{sec:membership-function}). This step is known as fuzzification (see
Section \ref{sec:fuzzification}). Afterwards, an inference is made based on a
set of rules (see Section \ref{sec:reasoning}). Lastly, the resulting fuzzy
output is mapped to a crisp output using the membership functions, in the
defuzzification step (see Section \ref{sec:defuzzification}).

\begin{figure}[tbh]
  \center
  \includegraphics[width=0.66\textwidth]{figure/fuzzy-system.png}
  \caption{A Fuzzy Logic system.}
  \label{fig:fuzzy-system}
\end{figure}

\subsection{Other approaches}

\section{Strengths and Weaknesses}

\subsection{Advantages and Disadvantages of Belief Networks}

Like any other computational formalism, Bayesian Networks offer certain
advantages and disadvantages. Advantages of Bayesian Networks include:

\begin{itemize}
  \item Transparent representation of causal relationships between variables
  which can facilitate understanding the causal relationships.
  
  \item Relatively easy recognition of dependencies and independencies between
  various nodes.
  
  \item Handling situations where the data set is incomplete since the model
  accounts for dependencies between all variables.
  
  \item Capable of being readily updated when a new knowledge (evidence) becomes
  available.
  
  \item Both predictive/deductive and diagnostic/abductive reasonings are
  possible.

  \item Computational tractability exists for most practical applications.
\end{itemize}

\noindent The followings are the disadvantage of using Bayesian Networks:

\begin{itemize}
  \item High level of effort is required to build network models where a
  significant amount of probability data is required as the number of nodes and
  links in the structure increase (possible large CPT sizes).
  
  \item Computationally intensive if the conditional independencies are not
  properly considered among the variables.
  
  \item Challenging to get experts' knowledge in the form of probability to
  build the network.
  
  \item No feedback loops in the Bayesian Network's structure which has an
  acyclic nature. This structure prevents typical feedback loops in design of
  Bayesian Network's models.
\end{itemize}

\subsection{Advantages and Disadvantages of Dempster-Shafer Theory}

Advantages of Dempster-Shafer theory are:

\begin{itemize}
  \item Addressing the concept of possibility.
  
  \item The ability to represent the concept of ignorance to allow one to
  specify a degree of ignorance in a situation, instead of being forced to
  supply prior probabilities.
  
  \item Consistent with classical probability theory.
  
  \item Distinguishing randomness from missing information.
  
  \item No required priori knowledge.
  
  \item Including an evidence combination rule which provides an operator to
  integrate multiple pieces of information from different sources.
\end{itemize}

\noindent Disadvantages of Dempster-Shafer theory are:

\begin{itemize}
  \item Computational complexity grows exponentially with the number of
  hypotheses (in original formulation).
  
  \item Small modifications of the evidence assignments may lead to a
  completely different conclusion which can lead to misleading and
  counter-intuitive results.
\end{itemize}

\subsection{Advantages and Disadvantages of Fuzzy Logic Theory}

Advantages of Fuzzy Logic theory are:

\begin{itemize}
  \item Describing algorithms in terms of a combination of numerics and
  linguistics.
  \item Capturing the concept of the ambiguity of information.
  \item Flexible and intuitive knowldge-base design.
  \item Easy computation.
  \item Relatively robust algorithms.
\end{itemize}

\noindent Disadvantages of Fuzzy Logic theory are:

\begin{itemize}
  \item Determining the exact fuzzy rules and membership functions is a hard
  task.
  \item Requires manual tuning to obtain a better result.
  \item Requires to tune many options in design of a system.
  \item The order of inference steps matters.
  \item After reasoning, it can be difficult to exactly interpret the membership
  value.
  \item Validation of a fuzzy knowledge-based is typically expensive.
\end{itemize}

\section{Applications of Bayesian Networks}

motion control - sensor fusion - modeling domain knowledge

In \cite{toussaint:bayesian-motion-planning} Toussaint proposes a new approach
to robotic motion control and planning based on probabilistic inference. His
method uses structured probabilistic models to represent the scenario and
efficient inference techniques (belief propagation) to solve planning problems.
He also uses Bayesian Networks to find solutions to problems combining multiple
criteria or sources of information (sensor fusion) beside using them to solve a
fusion problem on the motor level.

\cite{park:bn-service-robot} uses probabilistic modeling for service robots to
provide users with high-level context-aware services required in home
environment, and proposes a systematic modeling approach for modeling a number
of Bayesian networks.

In \cite{orozco:multisensor-bn} researchers have developed a system to integrate
indirect measures of different sensors. This system is designed based on a
Bayesian Network and can be applied to use any type of sensor which provides
measures of the robot's environment independent of sensor types, environment and
application of the robot.

In \cite{bourgault:operator-multiple-robot} authors use Bayesian Networks to
model interactions between humans and multiple semi-autonomous robots. They have
modeled discrete operator decisions as probabilistic Bayesian Network blocks
with conditional dependencies on individual system states.

In \cite{song:bn-service-robot} authors adopt Bayesian Networks and ontology
together for modeling domain knowledge and reasoning objects in probabilistic
framework for a service robot. In this work, they use objects as context
information for predicting target object being present, since it can be occluded
or small in indoor environments.

In \cite{dearden:forward-model-robot} researchers use a Bayesian Network to
represent a forward model of a robot's actions to predict the consequences of
the robot's actions on its own motor system and the environment.

Intention recognition for an intelligent human-robot interaciton
\cite{tahboub:hri-dbn}

mobile-robot localization \cite{zhou:mobile-robot-localization}
\cite{fox:bayesian-location}

autonomous reconstruction of 3D images for indoor mobile robots
\cite{delage:dbn-image-reconstruction}




In \cite{arinbjarnar:bn-agent-drama} researchers propose an efficient and
scalable Bayesian Network techniques using relevance reasoning, that are
suitable for the needs of their autonomous agents in directed emergent drama and
allow for real-time decision making. They do this by extracting only a relevant
part of the network and only update the values in this reduced network.

In \cite{xiang:dai-bn} Xiang extends Multiply Sectioned Bayesian Networks
(MSBNs) for single-agent systems into a framework for multi-agent distributed
interpretation systems. In this work, each cooperative agent is represented as a
Bayesian subnet that consumes its own computational resource, gathers its own
evidence, and can answer queries.




internal models in multi-agent setting \cite{nielsen:fusion-bn-mas}

knowledge representation of the agents \cite{bloemeke:agent-encapsulated-bn}
\cite{santos:cognitive-knowledge-representation}
\cite{martin:reasoning-action-bbn}

modeling theory of mind \cite{baker:bayesian-tom}
\cite{bello:cginitive-foundation-tom}

modeling trustworthiness of agents \cite{tan:trust-bbn}

\section{Conclusion}

\bibliographystyle{plain}
\bibliography{mshayganfar}

\end{document}




























