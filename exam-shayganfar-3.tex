\documentclass[11pt]{article}

\usepackage{graphicx}
%\usepackage{algorithmic}
%\usepackage{algorithm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[mathscr]{euscript}

\begin{document}

\pagenumbering{arabic}

\begin{center}
{\LARGE{\textbf{Uncertainty in Artificial Intelligence}}} \\
\Large\textsc{Ph.D. Comprehensive Exam} \\[1em]
\large\textnormal{Mohammad Shayganfar - mshayganfar@wpi.edu} \\
\large\textnormal{May, 26 2015}
\end{center}

\section{Introduction to Uncertainty in AI}

\section{Sources and Types of Uncertainties}

-Sources:

+ Noise (imprecise observation)

+ Uncertain Change (unprediatable or stochastis behavior of the world)

+ Incompleteness or igonorance (missing information)

\section{Theories of Uncertainties}

\subsection{Bayesian Networks}

\subsubsection{Types of Reasoning}

\subsubsection{Probability Theory}

\subsection{Dempster-Shafer Theory}

In \cite{dempster:theory}, Dempster proposed a probabilistic framework based on
lower and upper bounds on probabilities. In \cite{shafer:evidence-theory},
Shafer developed a formalism for reasoning under uncertaintythat used some of
Dempster's mathematical expressions, but gave them a different interpretation:
each piece of evidence (finding) may support a subset containing several
hypotheses. This is a generalization of the pure probabilistic framework in
which every finding corresponds to a value of a variable (a single hypothesis)
\cite{diez:reasoning-uncertainty}. Dempster-Shafer theory is the generalization
of the Bayesian theory of subjective probability (mainly by virtue of its
explicit definition of the concept of ignorance) to combine accumulative
evidence or to change prior oopinions in the light of new evidence
\cite{das:decision-making-agents}. Dempster-Shafer theory is designed to deal
with the distinction between uncertainty and ignorance. Rather than computing
the probability of a proposition, it computes the probability that the evidence
supports the proposition \cite{russell:ai-modern} and it does not require the
assumption that \textit{Bel}(A) + \textit{Bel}($\neg$A) = 1. Dempster-Shafer
theory deals with the possible values of an unknown variable, just as deos the
theory of probability \cite{tanimoto:ai-lisp}. 

This approach starts out with a \textit{belief function} (sometimes called a
support function). Given a set W of possible worlds and $U \subseteq W$, the
belief in U, denoted \textit{Bel}(\textit{U}), is a number in the interval [0,
1].

\subsection{Fuzzy Logic}

\subsection{Other approaches}

\section{Strengths and Weaknesses}

In general, there is an increasing trend of computational complexity Fuzzy Logic
to probabilistic approaches and Dempster-Shafer theory. However, the
representational power and precision increases in the same order and direction.

- Locality in rule-based systems vs. using all evidences in probabilistic
systems [R\&N AI book p.524]

-Detachment in rule-based systems vs. requiring the source of evidence for
subsequent probabilistic reasoning [R\&N AI book p.524]

- Dempster-Shafer theory allows no definite decision in many cases, whereas
probabilistic inference does yield a specific choice \cite{russell:ai-modern}.

- In contrast to Dempster-Shafer theory, a complete Bayesian model would include
probability estimates for factors that allow us to express the ignorance in
terms of how our beliefs would change in the face of future informaiton
gathering \cite{russell:ai-modern}.

\subsection{Advantages and Disadvantages of Belief Networks}

Like any other computational formalism, belief network technology offers certain
advantages and disadvantages. Advantages of belief networks include
\cite{das:decision-making-agents}:

\begin{itemize}
  \item Sound theoretical foundation: The computation of beliefs using
  probability estimates is guaranteed to be consistent with probability theory.
  This advantage stems from the Bayesian update procedureâ€™s strict derivation
  from the axioms of probability.
  \item Graphical models: Belief networks graphically depict the
  interdependencies that exist between related pieces of domain knowledge,
  enhancing understanding of the domain. The structure of a belief network
  captures the cause-effect relationships that exist amongst the variables of
  the domain. The ease of causal interpretation in belief network models
  typically makes them easier to construct than other models, minimizing the
  knowledge engineering costs and making them easier to modify.
  \item Predictive and diagnostic reasoning: Belief networks combine both
  deductive/predictive and abductive/diagnostic reasoning. Interdependencies
  among variables in a network are accurately captured and speculative if-then
  type computation can be performed.
  \item Computational tractability: Belief networks are computationally
  tractable for most practical applications. This efficiency stems principally
  from the exploitation of conditional independence relationships over the
  domain. We have presented an efficient single-pass evidence propagation
  algorithm for networks without loops.
  \item Evidence handling: Evidence can be posted to any node in a belief
  network. This means that subjective evidence can be posted at an intermediate
  node representing an abstract concept.
\end{itemize}

A major disadvantage of belief network technology is the high level of effort
required to build network models. Although it is relatively easy to build a
belief network structure with the help of subject matter experts, the model will
require a significant amount of probability data as the number of nodes and
links in the structure increase. The size of a CPT corresponding to a node with
multiple parents can potentially be huge. For example, the number of independent
entries in the CPT of a binary node (a node with two states) with 8 binary
parent variables is 128.

Belief networks are also poor at handling continuous variables. Current
software handles continuous variables in a very restrictive manner (for example,
they must be Gaussian and can only be children). Lener et al. (2001) developed
an inference algorithm for static hybrid belief networks, which are Conditional
Linear Gaussian models, where the conditional distribution of the continuous
variables assigned to the discrete variables is a multivariate Gaussian. Cob and
Shenoy (2004) developed an inference algorithm in hybrid belief networks using
Mixtures of Truncated Potentials. But these techniques are yet to be incorporated
in commercial software.

\subsection{Advantages and Disadvantages of Dempster-Shafer Theory}

- Represents the actual state of belief more precisely

- Distinguishes randomness from missing information

Dis:

- The main problem of the Dempster-Shafer theoryin its original formulation is
that its computational complexity grows exponentially with the number of
hypotheses.

- mathematically complex

- Has to be calculated over all possible sets of states

- A small modification of the evidence assignments may lead to a completely
different conclusion.

\subsection{Advantages and Disadvantages of Fuzzy Logic}

- Easy to design 

- Relatively intuitive rules 

- Relatively robust controllers 

Dis:

- Longer inference chains can be problematic 

- The order of inference steps matters

- After inference it can be difficult to exactly interpret the membership value 


\section{Applications of Bayesian Networks}

\section{Conclusion}

\bibliographystyle{plain}
\bibliography{mshayganfar}

\end{document}